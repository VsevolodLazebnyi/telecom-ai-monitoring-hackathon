import os
import json
import time
import threading
from datetime import datetime, timedelta

import requests
import pandas as pd
import streamlit as st
import redis
from loguru import logger

from handlers.gpt4free_handler import Gpt4FreeHandler
from handlers.grafana_handler import GrafanaHandler
from handlers.prometheus_handler import PrometheusHandler
from handlers.rabbitmq_handler import RabbitMQHandler
from handlers.vectordb_handler import VectorDBHandler

APP_TITLE = "–£–º–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å –ò–ò"
st.set_page_config(page_title=APP_TITLE, page_icon="üì°", layout="wide")

def get_default_envs():
    return {
        "PROMETHEUS_URL": os.getenv("PROMETHEUS_URL", "http://localhost:9090"),
        "GRAFANA_URL": os.getenv("GRAFANA_URL", "http://localhost:3000"),
        "GRAFANA_API_KEY": os.getenv("glsa_CR1KUKUEXjXsZsO72sGV0JGbJEm2Aj5y_4e2e5639", "glsa_CR1KUKUEXjXsZsO72sGV0JGbJEm2Aj5y_4e2e5639"),
        "REDIS_URL": os.getenv("REDIS_URL", "redis://:admin123@localhost:6379/0"),
        "RABBITMQ_URL": os.getenv("RABBITMQ_URL", "amqp://admin:admin123@localhost:5672/"),
        "GPT4FREE_URL": os.getenv("GPT4FREE_URL", "http://localhost:1337"),
    }

def init_session_state():
    if "cfg" not in st.session_state:
        st.session_state.cfg = get_default_envs()

    if "gpt" not in st.session_state:
        st.session_state.gpt = Gpt4FreeHandler(base_url=st.session_state.cfg["GPT4FREE_URL"])
    if "grafana" not in st.session_state:
        st.session_state.grafana = GrafanaHandler(
            grafana_host=st.session_state.cfg["GRAFANA_URL"],
            grafana_token=st.session_state.cfg["GRAFANA_API_KEY"],
        )
    if "prom" not in st.session_state:
        st.session_state.prom = PrometheusHandler(url=st.session_state.cfg["PROMETHEUS_URL"])
    if "vectordb" not in st.session_state:
        st.session_state.vectordb = VectorDBHandler()

    try:
        st.session_state.redis = redis.Redis.from_url(
            st.session_state.cfg["REDIS_URL"], decode_responses=True
        )
    except Exception as e:
        st.session_state.redis = None
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Redis: {e}")

    if "rabbit_consumer_started" not in st.session_state:
        st.session_state.rabbit_consumer_started = False

def sidebar_config():
    st.sidebar.header("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏—è")
    cfg = st.session_state.cfg

    cfg["PROMETHEUS_URL"] = st.sidebar.text_input("Prometheus URL", cfg["PROMETHEUS_URL"])
    cfg["GRAFANA_URL"] = st.sidebar.text_input("Grafana URL", cfg["GRAFANA_URL"])
    cfg["REDIS_URL"] = st.sidebar.text_input("Redis URL", cfg["REDIS_URL"])
    cfg["RABBITMQ_URL"] = st.sidebar.text_input("RabbitMQ URL", cfg["RABBITMQ_URL"])
    cfg["GPT4FREE_URL"] = st.sidebar.text_input("GPT4Free URL", cfg["GPT4FREE_URL"])

    col_a, col_b = st.sidebar.columns(2)
    if col_a.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å", use_container_width=True):
        st.session_state.gpt = Gpt4FreeHandler(base_url=cfg["GPT4FREE_URL"])
        st.session_state.grafana = GrafanaHandler(grafana_host=cfg["GRAFANA_URL"], grafana_token=cfg["GRAFANA_API_KEY"])
        st.session_state.prom = PrometheusHandler(url=cfg["PROMETHEUS_URL"])
        try:
            st.session_state.redis = redis.Redis.from_url(cfg["REDIS_URL"], decode_responses=True)
            st.success("–ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π —É—Å–ø–µ—à–Ω–æ.")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è Redis: {e}")

    if col_b.button("RabbitMQ", use_container_width=True, disabled=st.session_state.rabbit_consumer_started):
        try:
            def start_consumer():
                try:
                    RabbitMQHandler()
                except Exception as e_:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–æ—Ç–æ–∫–∞ Rabbit consumer: {e_}")

            t = threading.Thread(target=start_consumer, daemon=True)
            t.start()
            st.session_state.rabbit_consumer_started = True
            st.success("RabbitMQ consumer –∑–∞–ø—É—â–µ–Ω.")
        except Exception as e:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å consumer: {e}")

def check_prometheus(url: str) -> tuple[bool, str]:
    try:
        r = requests.get(f"{url}/api/v1/status/buildinfo", timeout=5)
        return (r.ok, f"{r.status_code}")
    except Exception as e:
        return (False, str(e))

def check_grafana(url: str, key: str) -> tuple[bool, str]:
    try:
        headers = {"Authorization": f"Bearer {key}"} if key else {}
        r = requests.get(f"{url}/api/health", headers=headers, timeout=5)
        return (r.ok, f"{r.status_code}")
    except Exception as e:
        return (False, str(e))

def check_redis(redis_client) -> tuple[bool, str]:
    try:
        if not redis_client:
            return (False, "–Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        pong = redis_client.ping()
        return (pong is True, "PONG" if pong else "–Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞")
    except Exception as e:
        return (False, str(e))

def check_rabbitmq(amqp_url: str) -> tuple[bool, str]:
    try:
        mgmt = "http://localhost:15672/api/overview"
        r = requests.get(mgmt, auth=("admin", "admin123"), timeout=5)
        return (r.ok, f"{r.status_code}")
    except Exception as e:
        return (False, str(e))

def check_gpt4free(url: str) -> tuple[bool, str]:
    try:
        payload = {
            "model": "gpt-4",
            "messages": [{"role": "user", "content": "ping"}],
            "max_tokens": 5,
            "temperature": 0.0,
        }
        r = requests.post(f"{url}/v1/chat/completions", json=payload, timeout=10)
        return (r.ok, f"{r.status_code}")
    except Exception as e:
        return (False, str(e))

def prom_instant_query(base_url: str, query: str):
    try:
        r = requests.get(f"{base_url}/api/v1/query", params={"query": query}, timeout=20)
        return r.ok, (r.json() if r.ok else r.text)
    except Exception as e:
        return False, str(e)

def prom_range_query(base_url: str, query: str, start: datetime, end: datetime, step: str = "15s"):
    try:
        params = {
            "query": query,
            "start": int(start.timestamp()),
            "end": int(end.timestamp()),
            "step": step,
        }
        r = requests.get(f"{base_url}/api/v1/query_range", params=params, timeout=30)
        return r.ok, (r.json() if r.ok else r.text)
    except Exception as e:
        return False, str(e)

def matrix_to_dataframe(result: list):
    rows = []
    for series in result:
        metric = series.get("metric", {})
        label = metric.get("instance") or metric.get("pod") or metric.get("__name__") or json.dumps(metric, ensure_ascii=False)
        for ts, val in series.get("values", []):
            ts_dt = datetime.fromtimestamp(float(ts))
            rows.append({"timestamp": ts_dt, "series": label, "value": float(val)})
    if not rows:
        return pd.DataFrame()
    df = pd.DataFrame(rows)
    pivot = df.pivot(index="timestamp", columns="series", values="value").sort_index()
    return pivot

def vector_to_dataframe(result: list):
    rows = []
    for series in result:
        metric = series.get("metric", {})
        value = series.get("value")
        val = float(value[1]) if value and len(value) > 1 else None
        rows.append({"metric": json.dumps(metric, ensure_ascii=False), "value": val})
    return pd.DataFrame(rows)

def tab_status():
    st.markdown("### –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã")
    cfg = st.session_state.cfg

    col1, col2, col3 = st.columns(3)
    with col1:
        ok, info = check_prometheus(cfg["PROMETHEUS_URL"])
        st.metric("Prometheus", "UP" if ok else "DOWN", delta=info)
    with col2:
        ok, info = check_grafana(cfg["GRAFANA_URL"], cfg["GRAFANA_API_KEY"])
        st.metric("Grafana", "UP" if ok else "DOWN", delta=info)
    with col3:
        ok, info = check_redis(st.session_state.redis)
        st.metric("Redis", "UP" if ok else "DOWN", delta=info)

    col4, col5 = st.columns(2)
    with col4:
        ok, info = check_rabbitmq(cfg["RABBITMQ_URL"])
        st.metric("RabbitMQ", "UP" if ok else "DOWN", delta=info)
    with col5:
        ok, info = check_gpt4free(cfg["GPT4FREE_URL"])
        st.metric("GPT4Free", "UP" if ok else "DOWN", delta=info)

def resolve_grafana_prometheus_uid_and_url():
    ds_uid = None
    prom_base_url = st.session_state.cfg["PROMETHEUS_URL"]

    if not st.session_state.cfg["GRAFANA_API_KEY"]:
        return ds_uid, prom_base_url

    try:
        datasources = st.session_state.grafana.fetch_datasources()
        prom_list = [d for d in datasources if d.get("typeName") == "Prometheus" or d.get("name") == "prometheus"]
        if prom_list:
            ds = prom_list[0]
            ds_uid = ds.get("uid")
        return ds_uid, prom_base_url
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å datasources –∏–∑ Grafana: {e}")
        return ds_uid, prom_base_url
    
def save_dashboard_to_provisioning(dashboard_json, filename):
    dashboard_dir = "./generated_dashboards"
    os.makedirs(dashboard_dir, exist_ok=True)
    safe_filename = "".join(c for c in filename if c.isalnum() or c in (' ', '-', '_')).rstrip()
    safe_filename = safe_filename.replace(' ', '_') + ".json"
    
    filepath = os.path.join(dashboard_dir, safe_filename)
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(dashboard_json, f, indent=2, ensure_ascii=False)
        
        logger.info(f"–î–∞—à–±–æ—Ä–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filepath}")
        return filepath
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞—à–±–æ—Ä–¥–∞: {e}")
        return None

def tab_metrics_vectordb():
    st.markdown("### –ö–∞—Ç–∞–ª–æ–≥ –º–µ—Ç—Ä–∏–∫ –∏ VectorDB")

    ds_uid, prom_url = resolve_grafana_prometheus_uid_and_url()
    if ds_uid:
        st.success(f"Grafana Prometheus DS UID: {ds_uid}")
    else:
        st.info("Grafana API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ Prometheus datasource –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    ds_uid_input = st.text_input("Datasource UID", ds_uid or "default")

    if st.button("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ ‚Üí VectorDB"):
        try:
            count = st.session_state.prom.fetch_metrics_data(
                ds={"uid": ds_uid_input},
                vectordbs_handler=st.session_state.vectordb,
            )
            st.success(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –Ω–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫: {count}")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")

    st.divider()
    st.markdown("#### –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –º–µ—Ç—Ä–∏–∫")
    examples = st.text_input("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é")
    topn = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", 1, 10, 3)
    if st.button("üîç –ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ"):
        names = [x.strip() for x in examples.split(",") if x.strip()]
        if not names:
            st.warning("–í–≤–µ–¥–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞.")
        else:
            sims = st.session_state.vectordb.query_metrics_batch(names, ds_uid=ds_uid_input, n_results=topn)
            if sims:
                st.success(f"–ü–æ—Ö–æ–∂–∏–µ –º–µ—Ç—Ä–∏–∫–∏ ({len(sims)}):")
                st.write(sims)
            else:
                st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

def tab_ai_dashboard():
    st.markdown("### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—à–±–æ—Ä–¥–æ–≤ —Å –ò–ò")
    
    if not st.session_state.grafana.test_connection():
        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Grafana. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL –∏ —Ç–æ–∫–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö.")
        return
    
    ds_uid, prom_url = resolve_grafana_prometheus_uid_and_url()
    ds_uid = ds_uid or "default"
    
    st.info("üí° –û–ø–∏—à–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        dashboard_queries = st.text_area(
            "–ó–∞–ø—Ä–æ—Å—ã –¥–ª—è –ø–∞–Ω–µ–ª–µ–π:",
            height=150,
            placeholder="–ó–∞–≥—Ä—É–∑–∫–∞ CPU –ø–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ Redis\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ HTTP –∑–∞–ø—Ä–æ—Å–æ–≤\n–û—à–∏–±–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î"
        )
        
    with col2:
        dashboard_title = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–∞", "AI-dashboard")
        time_range = st.selectbox("–í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω", ["1h", "6h", "24h", "7d"], index=1)
        
        folders = st.session_state.grafana.get_folders()
        folder_options = {0: "AI Generated Dashboards"}
        for folder in folders:
            folder_options[folder['id']] = folder['title']
        
        selected_folder = st.selectbox("–ü–∞–ø–∫–∞", options=list(folder_options.keys()), 
                                     format_func=lambda x: folder_options[x])

    if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞—à–±–æ—Ä–¥", type="primary"):
        if not dashboard_queries.strip():
            st.warning("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –ø–∞–Ω–µ–ª–µ–π")
            return
            
        queries = [q.strip() for q in dashboard_queries.split("\n") if q.strip()]
        if not queries:
            st.warning("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
            return
            
        st.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—à–±–æ—Ä–¥–∞ —Å {len(queries)} –ø–∞–Ω–µ–ª—è–º–∏...")
        
        panels = []
        errors = []
        
        with st.status("–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–Ω–µ–ª–µ–π...", expanded=True) as status:
            for i, query in enumerate(queries):
                status.write(f"–ü–∞–Ω–µ–ª—å {i+1}: {query}")
                
                user_query_map = {
                    "mandatory_datasource_uuid": ds_uid,
                    "userquery": query,
                    "time_range": time_range,
                    "hints": ["use available metric names", "prefer standard exporters"]
                }
                
                promql_result = st.session_state.gpt.generate_promql_query(user_query_map)
                
                if "error" in promql_result:
                    errors.append(f"‚ùå '{query}': {promql_result['error']}")
                    continue
                    
                try:
                    result_arr = promql_result.get("result", [])
                    if not result_arr:
                        errors.append(f"‚ùå '{query}': –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò")
                        continue
                        
                    promql = result_arr[0].get("query", "")
                    if not promql:
                        errors.append(f"‚ùå '{query}': –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω PromQL")
                        continue
                        
                    if any(op in promql.lower() for op in ["rate(", "increase(", "histogram_quantile"]):
                        panel_type = "timeseries"
                        format_type = "time_series"
                    else:
                        panel_type = "stat"
                        format_type = "table"
                    
                    panel = {
                        "title": query[:80],
                        "datasource": {"type": "prometheus", "uid": ds_uid},
                        "query": promql,
                        "format": format_type,
                        "vis_type": panel_type,
                        "gridPos": {"x": (i % 2) * 12, "y": (i // 2) * 8, "w": 12, "h": 8}
                    }
                    panels.append(panel)
                    status.write(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–Ω–µ–ª—å —Å PromQL: `{promql[:50]}...`")
                    
                except Exception as e:
                    errors.append(f"‚ùå '{query}': –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ - {str(e)}")
            
            if errors:
                status.update(label="–ó–∞–≤–µ—Ä—à–µ–Ω–æ —Å –æ—à–∏–±–∫–∞–º–∏", state="error")
                st.error("–û—à–∏–±–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:")
                for error in errors:
                    st.write(error)
            else:
                status.update(label="–í—Å–µ –ø–∞–Ω–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã!", state="complete")
        
        if panels:
            with st.status("–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–∞...", expanded=True) as status:
                status.write("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞—à–±–æ—Ä–¥–∞...")
                
                dashboard_data = {
                    "dashboard_title": dashboard_title,
                    "time_range": time_range,
                    "panels": panels
                }
                
                dash_json = st.session_state.gpt.generate_grafana_dashboard(dashboard_data)
                
                if "error" in dash_json:
                    status.update(label="–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞—à–±–æ—Ä–¥–∞", state="error")
                    st.error(f"–û—à–∏–±–∫–∞: {dash_json['error']}")
                    return
                
                status.update(label="–î–∞—à–±–æ—Ä–¥ —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω!", state="complete")
            
            with st.expander("üìã –ü—Ä–æ—Å–º–æ—Ç—Ä —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ JSON"):
                st.json(dash_json)
            
            st.markdown("---")
            st.subheader("–ò–º–ø–æ—Ä—Ç –≤ Grafana")
            
            col_import1, col_import2 = st.columns([1, 1])
            
            with col_import1:
                if st.button("üìÅ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ Grafana", use_container_width=True, 
                           help="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞—à–±–æ—Ä–¥ –≤ —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≤–∏–∂–∏–Ω–∏–Ω–≥–∞ Grafana"):
                    filepath = save_dashboard_to_provisioning(dash_json, dashboard_title)
                    if filepath:
                        st.success(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: `{filepath}`")
                    else:
                        st.error("‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –¥–∞—à–±–æ—Ä–¥–∞")
            
            with col_import2:
                st.download_button(
                    label="üíæ –°–∫–∞—á–∞—Ç—å JSON",
                    data=json.dumps(dash_json, indent=2, ensure_ascii=False),
                    file_name=f"{dashboard_title.lower().replace(' ', '_')}.json",
                    mime="application/json",
                    use_container_width=True
                )

def tab_alerts_logs():
    st.markdown("### –ò–ò –∞–Ω–∞–ª–∏–∑")
    col_r1, col_r2 = st.columns([1, 1])
    with col_r1:
        limit = st.slider("–°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –æ–ø–æ–≤–µ—â–µ–Ω–∏–π –ø–æ–∫–∞–∑–∞—Ç—å", 10, 200, 50, 10)
    with col_r2:
        analyze_ai = st.checkbox("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–ø–æ–≤–µ—â–µ–Ω–∏—è —Å –ò–ò", value=False)
    
    if st.button("–û–±–Ω–æ–≤–∏—Ç—å —Å–µ–π—á–∞—Å"):
        if hasattr(st, "rerun"):
            st.rerun()
        else:
            st.experimental_rerun()
            
    try:
        r = st.session_state.redis
        if not r:
            st.error("Redis –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
            return
            
        cursor = 0
        keys = []
        while True:
            cursor, batch = r.scan(cursor=cursor, match="alert:*", count=500)
            keys.extend(batch)
            if cursor == 0:
                break
        keys_sorted = sorted(keys, reverse=True)[:limit]
        if not keys_sorted:
            st.info("–û–ø–æ–≤–µ—â–µ–Ω–∏–π –ø–æ–∫–∞ –Ω–µ—Ç.")
            return
            
        items = []
        for k in keys_sorted:
            try:
                val = r.get(k)
                if val:
                    items.append(json.loads(val))
            except Exception:
                continue
                
        for alert in items:
            severity = alert.get("severity", "INFO")
            color = {
                "CRITICAL": "üü•",
                "HIGH": "üüß",
                "WARNING": "üü®",
                "MEDIUM": "üü®",
                "INFO": "üü¶",
            }.get(severity, "‚¨ú")
            st.write(f"{color} [{alert.get('timestamp','')}] {alert.get('type','')}")
            st.json(alert, expanded=False)
            if analyze_ai:
                with st.spinner("–ê–Ω–∞–ª–∏–∑ –ò–ò..."):
                    explanation = st.session_state.gpt.analyze_alert_with_ai(alert)
                st.markdown("**–ê–Ω–∞–ª–∏–∑ –ò–ò:**")
                st.write(explanation)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑ Redis: {e}")

def main():
    init_session_state()
    sidebar_config()
    st.title(APP_TITLE)
    tabs = st.tabs([
        "–ò–ò ‚Üí –î–∞—à–±–æ—Ä–¥—ã",
        "–û–ø–æ–≤–µ—â–µ–Ω–∏—è –∏ –ª–æ–≥–∏", 
        "–°—Ç–∞—Ç—É—Å",
        "–ö–∞—Ç–∞–ª–æ–≥ –º–µ—Ç—Ä–∏–∫"
    ])
    with tabs[0]: tab_ai_dashboard()
    with tabs[1]: tab_alerts_logs()
    with tabs[2]: tab_status()
    with tabs[3]: tab_metrics_vectordb()
    

if __name__ == "__main__":
    main()